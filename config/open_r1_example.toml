[common]
    seed = 42

[model]
    model_name_or_path = "Qwen/Qwen3-8B-Base"
    dtype = "bfloat16"

[peft]
    use_peft = true
    task_type = "CAUSAL_LM"
    use_dora = true
    r = 8
    lora_alpha = 32
    lora_dropout = 0.1
    target_modules = ["q_proj", "v_proj", "k_proj", "o_proj", "up_proj", "down_proj"]

[training]
    learning_rate = 1e-6
    output_dir = ""
    run_name = "grpo-lora-qwen3-0.6b"
    remove_unused_columns = false
    gradient_accumulation_steps = 16
    num_train_epochs = 1
    max_completion_length = 64
    num_generations = 4
    max_prompt_length = 128
    logging_steps = 10
    save_strategy = "steps"
    save_steps = 10
    use_vllm = false # do not use vllm and rollout w/ model.generate instead
    use_liger_kernel = true
    loss_type = "grpo"

[dataset]
    dataset_name_or_path = "HuggingFaceH4/OpenR1-Math-220k-default-verified"
    example_numbers = 1e9 # use all examples